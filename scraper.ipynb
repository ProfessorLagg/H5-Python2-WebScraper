{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7b72c9",
   "metadata": {},
   "source": [
    "# Notes\n",
    "##### All Items Have\n",
    "- id\n",
    "- level _(can be 0)_\n",
    "- name\n",
    "- icon\n",
    "- quality\n",
    "- class\n",
    "- subclass\n",
    "##### Items can have\n",
    "- __Equipment Info__\n",
    "  - Equip Slot\n",
    "  - __Weapon Stats__\n",
    "    - dmgmin\n",
    "    - dmgmax\n",
    "    - speed\n",
    "    - dps _(can be meta data)_\n",
    "  - __Attributes__\n",
    "    - __Primary Attributes__\n",
    "      - Strength\n",
    "      - Agility\n",
    "      - Intellect\n",
    "      - Stamina\n",
    "      - Spirit\n",
    "      - Armor\n",
    "    - __Secondary Attributes__\n",
    "      - Melee/Ranged/Spell/All Critical Strike Rating\n",
    "      - Melee/Ranged/Spell/All Hit Rating\n",
    "      - Melee/Ranged/All Attack Power\n",
    "      - Healing/Damage/All Spell Power \n",
    "- Vendor Sell Price\n",
    "\n",
    "## Links\n",
    "- [Extentions in Webdriver](https://www.reddit.com/r/learnpython/comments/4zzn69/how_do_i_get_adblockplus_to_work_with_selenium/)\n",
    "- [requests docs](https://requests.readthedocs.io/en/latest/)\n",
    "- [tqdm docs](https://tqdm.github.io/)\n",
    "- [concurrent.futures docs](https://docs.python.org/dev/library/concurrent.futures.html)\n",
    "- [seaborn docs](https://seaborn.pydata.org/api.html)\n",
    "- [chrome switches](https://stackoverflow.com/questions/38335671/where-can-i-find-a-list-of-all-available-chromeoption-arguments)\n",
    "- [mathplotlib docs](https://matplotlib.org/stable/api/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import concurrent.futures\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267bdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# root_url = r'https://www.wowhead.com/wotlk'\n",
    "root_url = r'https://www.wowhead.com/cata'\n",
    "output_dir = r'output'\n",
    "\n",
    "min_itemlvl = 0\n",
    "max_itemlvl = 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "driver_options = webdriver.chrome.options.Options()\n",
    "driver_options.page_load_strategy = 'normal'\n",
    "driver_options.add_argument(r'--headless')\n",
    "driver = webdriver.Chrome(options=driver_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape item quality and build itemlist links\n",
    "def process_item_quality_elem(elem):\n",
    "    _id = int(elem.get_attribute(\"value\"))\n",
    "    _name = elem.text\n",
    "    _color = elem.value_of_css_property(\"color\")\n",
    "    _color = _color[_color.index('(') + 1:]\n",
    "    _color = _color[:_color.index(')')]\n",
    "    _color_split = _color.split(', ')\n",
    "    _color = '#' + \"{:02x}\".format(int(_color_split[0])) + \"{:02x}\".format(\n",
    "        int(_color_split[1])) + \"{:02x}\".format(int(_color_split[2]))\n",
    "    return {\"id\": _id, \"name\": _name, \"color\": _color}\n",
    "\n",
    "item_qualities_csv_path = Path(output_dir + \"/item_qualities.csv\")\n",
    "item_qualities_csv_exists = item_qualities_csv_path.exists()\n",
    "\n",
    "if(item_qualities_csv_exists):\n",
    "    item_qualities = pd.read_csv(item_qualities_csv_path, sep=';')\n",
    "else:\n",
    "    items_url = root_url + \"/items\"\n",
    "    driver.get(items_url)\n",
    "    item_quality_elems = driver.find_elements(\n",
    "        By.CSS_SELECTOR, '#filter-facet-quality > option')\n",
    "    item_qualities = pd.DataFrame.from_records(\n",
    "        [process_item_quality_elem(e) for e in item_quality_elems],\n",
    "        index='id'\n",
    "    )\n",
    "    item_qualities.to_csv(item_qualities_csv_path, sep=';')\n",
    "item_qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9be333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close selenium web driver since we're done using it\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a045058",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_qualities_palette = sns.color_palette(item_qualities['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f67960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_itemlist_url(item_level, quality_id=None):\n",
    "    result = f\"{root_url}/items/min-level:{item_level}/max-level:{item_level}\"\n",
    "    if quality_id != None:\n",
    "        result += f\"/quality:{quality_id}\"\n",
    "    return result\n",
    "\n",
    "itemlist_ilvl_urls = {i:get_itemlist_url(i) for i in range(min_itemlvl, max_itemlvl)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da024a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filepath):\n",
    "    rsp = requests.get(url)\n",
    "    rsp.raise_for_status()\n",
    "    Path(str(filepath)).write_bytes(rsp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Item list data\n",
    "def process_itemlist(url):\n",
    "    rsp = requests.get(url)\n",
    "    rsp.raise_for_status()\n",
    "    match_iter = re.findall(r\"WH\\.Gatherer\\.addData\\(.*?\\);\", rsp.text, re.MULTILINE)\n",
    "    results = []\n",
    "    for m in match_iter:\n",
    "        json_str = m[m.index(r'WH.Gatherer.addData('):]\n",
    "        json_str = json_str[json_str.index(r'{'):]\n",
    "        json_str = json_str.rstrip(r');')\n",
    "        json_obj = json.loads(json_str)\n",
    "        results.append(json_obj)\n",
    "    result = []\n",
    "    for row in results:\n",
    "        for k in row.keys():\n",
    "            record = record = {'item_id':int(k)} | row[k]\n",
    "            result.append(record)\n",
    "    return result\n",
    "\n",
    "itemlist_datas = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=(os.cpu_count() - 1)) as executor:\n",
    "    unprocessed = {u:None for u in itemlist_ilvl_urls.values()}\n",
    "    fail_count = {u:0 for u in itemlist_ilvl_urls.values()}\n",
    "    while len(unprocessed) > 0:\n",
    "        urls = [u for u in unprocessed.keys()]\n",
    "        futures = {executor.submit(process_itemlist, u):u for u in urls}\n",
    "        for f in tqdm(iterable=concurrent.futures.as_completed(futures),desc=\"Downloading itemlist data\", leave=False, total=len(futures)):\n",
    "            u = futures[f]\n",
    "            u_is_qualitylink = u.find(r'/quality:') >= 0\n",
    "            try:\n",
    "                data = f.result()\n",
    "            except Exception as e:\n",
    "                fail_count[u] += 1\n",
    "                if(fail_count[u] > 2):\n",
    "                    unprocessed.pop(u, None)\n",
    "                    print(f\"Could not process itemlist {u} due to exception: {e}\")\n",
    "                continue\n",
    "            else:\n",
    "                unprocessed.pop(u, None)\n",
    "                if len(data) < 1000 or u_is_qualitylink:\n",
    "                    itemlist_datas += data\n",
    "                elif u_is_qualitylink:\n",
    "                    print(f\"Even filtering on quality did not bring item count below 1000 for url {u}\")\n",
    "                    itemlist_datas += data\n",
    "                else:\n",
    "                    for qid in item_qualities.index:\n",
    "                        qu = f\"{u}/quality:{qid}\"\n",
    "                        unprocessed[qu] = None\n",
    "                        fail_count[qu] = 0\n",
    "                \n",
    "itemlist_datas = pd.DataFrame.from_records(itemlist_datas)\n",
    "itemlist_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_xml_dir = Path(output_dir + \"/itemxml\")\n",
    "item_xml_dir.mkdir(parents=True, exist_ok=True)\n",
    "item_xml_paths = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    missing_item_xml_urls = {}\n",
    "    for item_id in itemlist_datas['item_id']:\n",
    "        filepath_jpg = item_xml_dir.joinpath(f\"{item_id}.xml\").absolute()\n",
    "        if not filepath_jpg.exists():\n",
    "            missing_item_xml_urls[f\"{root_url}/item={item_id}&xml\"] = filepath_jpg\n",
    "        else:\n",
    "            item_xml_paths.append(filepath_jpg)\n",
    "    \n",
    "    while len(missing_item_xml_urls) > 0:\n",
    "        futures = {}\n",
    "        for url, filepath_jpg in tqdm(iterable=missing_item_xml_urls.items(), desc=\"Starting download item XML futures\", leave=False, total=len(missing_item_xml_urls)):\n",
    "            futures[executor.submit(download_file, url, filepath_jpg)] = url\n",
    "\n",
    "        for f in tqdm(iterable=concurrent.futures.as_completed(futures), desc=\"Downloading Item XML\", total=len(futures), leave=False):\n",
    "            url = futures[f]\n",
    "            filepath_jpg = missing_item_xml_urls[url]\n",
    "            try:\n",
    "                rsp = f.result()\n",
    "                rsp.raise_for_status()\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                missing_item_xml_urls.pop(url, None)\n",
    "                item_xml_paths.append(filepath_jpg)\n",
    "\n",
    "item_xml_paths = pd.Series(item_xml_paths)\n",
    "item_xml_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing item XML\n",
    "json_dir = Path(output_dir + \"/itemjson\")\n",
    "json_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "jsonequip_dir = Path(output_dir + \"/jsonequip\")\n",
    "jsonequip_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "htmltooltip_dir = Path(output_dir + \"/htmltooltip\")\n",
    "htmltooltip_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def parse_item_xml(path, overwrite=False):\n",
    "    root = ET.parse(path).find(\".//item\")\n",
    "    class_elem = root.find(\"class\")\n",
    "    subclass_elem = root.find(\"subclass\")\n",
    "    quality_elem = root.find(\"quality\")\n",
    "    icon_elem = root.find(\"icon\")\n",
    "    inventorySlot_elem = root.find(\"inventorySlot\")\n",
    "    parsedItem = {\n",
    "        \"id\": int(root.attrib['id']),\n",
    "        \"name\": root.findtext(\"name\"),\n",
    "        \"level\": int(root.findtext(\"level\")),\n",
    "        \"quality_id\": int(quality_elem.attrib['id']),\n",
    "        \"quality_name\": quality_elem.text,\n",
    "        \"class_id\": int(class_elem.attrib['id']),\n",
    "        \"class_name\": class_elem.text,\n",
    "        \"subclass_id\": int(subclass_elem.attrib['id']),\n",
    "        \"subclass_name\": subclass_elem.text,\n",
    "        \"icon_displayId\": int(icon_elem.attrib['displayId']),\n",
    "        \"icon_name\": icon_elem.text,\n",
    "        \"inventorySlot_id\": int(inventorySlot_elem.attrib['id']),\n",
    "        \"inventorySlot_name\": inventorySlot_elem.text,\n",
    "        \"link\": root.findtext(\"link\")\n",
    "    }\n",
    "    json_str = root.findtext(\"json\")\n",
    "    if (json_str):\n",
    "        json_filepath = json_dir.joinpath(\"{}.json\".format(parsedItem['id']))\n",
    "        if(not json_filepath.exists() or overwrite):\n",
    "            json_filepath.write_text('{' + json_str + '}')\n",
    "\n",
    "    jsonequip_str = root.findtext(\"jsonEquip\")\n",
    "    if (jsonequip_str):         \n",
    "        jsonequip_filepath = jsonequip_dir.joinpath(\"{}.equip.json\".format(parsedItem['id']))\n",
    "        if(not jsonequip_filepath.exists() or overwrite):\n",
    "            jsonequip_filepath.write_text('{' + jsonequip_str + '}')\n",
    "\n",
    "    htmltooltip_str = root.findtext('htmlTooltip')\n",
    "    if (htmltooltip_str):\n",
    "        htmltooltip_filepath = htmltooltip_dir.joinpath(\"{}.htm\".format(parsedItem['id']))\n",
    "        if(not htmltooltip_filepath.exists() or overwrite):\n",
    "            htmltooltip_filepath.write_text(htmltooltip_str)\n",
    "    return parsedItem\n",
    "\n",
    "fail_count = 0\n",
    "parsed_item_xml = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(parse_item_xml, p) for p in item_xml_paths]\n",
    "    for f in tqdm(iterable=concurrent.futures.as_completed(futures), desc=\"Parsing Item XML\", total=len(futures), leave=False):\n",
    "        try:\n",
    "            fres = f.result()\n",
    "        except:\n",
    "            fail_count += 1\n",
    "        else:\n",
    "            parsed_item_xml.append(fres)\n",
    "\n",
    "items = pd.DataFrame.from_records(parsed_item_xml, index='id')\n",
    "items.to_csv(output_dir + \"/items.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape and download icons\n",
    "icon_dir = Path(output_dir + \"/icons\")\n",
    "icon_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "icon_filepaths = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    missing_icons = {}\n",
    "    for icon_name in tqdm(iterable=items['icon_name'], desc=\"Collecting missing icons\", leave=False):\n",
    "        filepath_jpg = icon_dir.joinpath(f\"{icon_name}.jpg\").absolute()\n",
    "        if not filepath_jpg.exists():\n",
    "            missing_icons[f'https://wow.zamimg.com/images/wow/icons/large/{icon_name}.jpg'] = filepath_jpg\n",
    "        else:\n",
    "            icon_filepaths.append(filepath_jpg)\n",
    "\n",
    "        filepath_png = icon_dir.joinpath(f\"{icon_name}.png\").absolute()\n",
    "        if not filepath_png.exists():\n",
    "            missing_icons[f'https://wow.zamimg.com/images/wow/icons/large/{icon_name}.png'] = filepath_png\n",
    "        else:\n",
    "            icon_filepaths.append(filepath_png)\n",
    "    \n",
    "    while len(missing_icons) > 0:\n",
    "        futures = {}\n",
    "        for url, filepath_jpg in tqdm(iterable=missing_icons.items(), desc=\"Starting icon download futures\", leave=False, total=len(missing_icons)):\n",
    "            futures[executor.submit(download_file, url, filepath_jpg)] = url\n",
    "\n",
    "        for f in tqdm(iterable=concurrent.futures.as_completed(futures), desc=\"Downloading Icons\", total=len(futures), leave=False):\n",
    "            url = futures[f]\n",
    "            filepath_jpg = missing_icons[url]\n",
    "            try:\n",
    "                rsp = f.result()\n",
    "                rsp.raise_for_status()\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                icon_filepaths.append(filepath_jpg)\n",
    "            finally:\n",
    "                missing_icons.pop(url, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72984af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_jsonequip(fp):\n",
    "        with fp.open() as f:\n",
    "            data = json.load(f)\n",
    "            data[\"item_id\"] = int(Path(fp.stem).stem)\n",
    "            return data\n",
    "\n",
    "jsonequips_wide = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for fp in tqdm(iterable=jsonequip_dir.iterdir(), desc=\"Starting jsonequip parse futures\", leave=False):\n",
    "        futures.append(executor.submit(parse_jsonequip, fp))\n",
    "\n",
    "    for f in tqdm(iterable=concurrent.futures.as_completed(futures), desc=\"Parsing item jsonequips\", total=len(futures), leave=False):\n",
    "        ds = f.result()\n",
    "        jsonequips_wide.append(ds)\n",
    "\n",
    "jsonequips_wide = pd.DataFrame.from_records(jsonequips_wide).drop(columns={'appearances','displayid'}).sort_index()\n",
    "jsonequips_wide.set_index('item_id', inplace=True)\n",
    "jsonequips_wide.to_csv(output_dir + \"/jsonequips_wide.csv\", sep=';')\n",
    "jsonequips_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b388550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert jsonequips to long format\n",
    "jsonequips_long = []\n",
    "for item_id in jsonequips_wide.index:\n",
    "    ds = jsonequips_wide.loc[item_id].dropna()\n",
    "    for name in ds.index:\n",
    "        value = ds[name]\n",
    "        jsonequips_long.append(\n",
    "            {\"item_id\": item_id, \"property\": name, \"value\": value}\n",
    "        )\n",
    "\n",
    "jsonequips_long = pd.DataFrame.from_records(jsonequips_long, index='item_id').sort_index()\n",
    "jsonequips_long.to_csv(output_dir + \"/jsonequips_long.csv\", sep=';')\n",
    "jsonequips_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weapon_dps(item_id):\n",
    "        try:\n",
    "            row = jsonequips_wide.loc[item_id]\n",
    "        except:\n",
    "            return pd.NA\n",
    "        else:\n",
    "            if pd.notna(row['dps']):\n",
    "                return row['dps']\n",
    "            if pd.notna(row['mledps']):\n",
    "                print(\"used mledps\")\n",
    "                return row['mledps']\n",
    "            if pd.notna(row['rgddps']):\n",
    "                print(\"used rgddps\")\n",
    "                return row['rgddps']\n",
    "            # TODO Calculate from damage and speed numbers if all else fails\n",
    "            return pd.NA\n",
    "\n",
    "weapons = items[items['class_name'] == 'Weapons'][['subclass_name','name', 'level','quality_id','quality_name']].reset_index()\n",
    "weapons.rename(columns={'subclass_name':'subclass', 'quality_name':'quality', 'level':'item level', 'id':'item_id'}, inplace=True)\n",
    "\n",
    "weapons['quality_color'] = pd.Series([(lambda qid: item_qualities_palette[qid])(qid) for qid in weapons['quality_id']])\n",
    "weapons['dps'] = pd.Series([get_weapon_dps(item_id) for item_id in weapons['item_id']])\n",
    "weapons = weapons[weapons['dps'].notna()].sort_values('item_id', ascending=True).reset_index().drop(columns='index')\n",
    "weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weapons_by_subclass = {}\n",
    "for subclass in weapons['subclass'].drop_duplicates().sort_values():\n",
    "    weapons_by_subclass[subclass] = weapons[weapons['subclass'] == subclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(rc={'figure.figsize':(16,9)})\n",
    "sns.lineplot(data=weapons_by_subclass['Daggers'], x='item level',y='dps', hue='quality_color', legend=None, sort=True).set_title('Daggers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
