{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7b72c9",
   "metadata": {},
   "source": [
    "# Notes\n",
    "##### All Items Have\n",
    "- id\n",
    "- level _(can be 0)_\n",
    "- name\n",
    "- icon\n",
    "- quality\n",
    "- class\n",
    "- subclass\n",
    "##### Items can have\n",
    "- __Equipment Info__\n",
    "  - Equip Slot\n",
    "  - __Weapon Stats__\n",
    "    - dmgmin\n",
    "    - dmgmax\n",
    "    - speed\n",
    "    - dps _(can be meta data)_\n",
    "  - __Attributes__\n",
    "    - __Primary Attributes__\n",
    "      - Strength\n",
    "      - Agility\n",
    "      - Intellect\n",
    "      - Stamina\n",
    "      - Spirit\n",
    "      - Armor\n",
    "    - __Secondary Attributes__\n",
    "      - Melee/Ranged/Spell/All Critical Strike Rating\n",
    "      - Melee/Ranged/Spell/All Hit Rating\n",
    "      - Melee/Ranged/All Attack Power\n",
    "      - Healing/Damage/All Spell Power \n",
    "- Vendor Sell Price\n",
    "\n",
    "## Links\n",
    "- [Extentions in Webdriver](https://www.reddit.com/r/learnpython/comments/4zzn69/how_do_i_get_adblockplus_to_work_with_selenium/)\n",
    "- [requests docs](https://requests.readthedocs.io/en/latest/)\n",
    "- [tqdm docs](https://tqdm.github.io/)\n",
    "- [concurrent.futures docs](https://docs.python.org/dev/library/concurrent.futures.html)\n",
    "- [seaborn docs](https://seaborn.pydata.org/api.html)\n",
    "- [chrome switches](https://stackoverflow.com/questions/38335671/where-can-i-find-a-list-of-all-available-chromeoption-arguments)\n",
    "- [mathplotlib docs](https://matplotlib.org/stable/api/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import concurrent.futures\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267bdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "root_url = r'https://www.wowhead.com/wotlk'\n",
    "output_dir = r'output'\n",
    "\n",
    "min_itemlvl = 0\n",
    "max_itemlvl = 284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "driver_options = webdriver.chrome.options.Options()\n",
    "driver_options.page_load_strategy = 'normal'\n",
    "driver_options.add_argument(r'--headless')\n",
    "driver = webdriver.Chrome(options=driver_options)\n",
    "\n",
    "# Setup item scraping\n",
    "items_url = root_url + \"/items\"\n",
    "driver.get(items_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape item quality and build itemlist links\n",
    "def process_item_quality_elem(elem):\n",
    "    _id = int(elem.get_attribute(\"value\"))\n",
    "    _name = elem.text\n",
    "    _color = elem.value_of_css_property(\"color\")\n",
    "    _color = _color[_color.index('(') + 1:]\n",
    "    _color = _color[:_color.index(')')]\n",
    "    _color_split = _color.split(', ')\n",
    "    _color = '#' + \"{:02x}\".format(int(_color_split[0])) + \"{:02x}\".format(\n",
    "        int(_color_split[1])) + \"{:02x}\".format(int(_color_split[2]))\n",
    "    return {\"id\": _id, \"name\": _name, \"color\": _color}\n",
    "\n",
    "item_qualities_csv_path = Path(output_dir + \"/item_qualities.csv\")\n",
    "item_qualities_csv_exists = item_qualities_csv_path.exists()\n",
    "\n",
    "if(item_qualities_csv_exists):\n",
    "    item_qualities = pd.read_csv(item_qualities_csv_path, sep=';')\n",
    "else:\n",
    "    item_quality_elems = driver.find_elements(\n",
    "        By.CSS_SELECTOR, '#filter-facet-quality > option')\n",
    "    item_qualities = pd.DataFrame.from_records(\n",
    "        [process_item_quality_elem(e) for e in item_quality_elems],\n",
    "        index='id'\n",
    "    )\n",
    "    item_qualities.to_csv(item_qualities_csv_path, sep=';')\n",
    "\n",
    "item_qualities_palette = sns.color_palette(item_qualities['color'])\n",
    "\n",
    "itemlist_urls = []\n",
    "for quality in item_qualities.itertuples():\n",
    "    for itemlvl in range(min_itemlvl, max_itemlvl):\n",
    "        itemlist_url = \"{u}/min-level:{l:n}/max-level:{l:n}/quality:{q:n}\".format(\n",
    "            u=items_url,\n",
    "            l=itemlvl,\n",
    "            q=quality.Index\n",
    "        )\n",
    "        itemlist_urls.append(itemlist_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemlist_data_rgx1 = r'WH\\.Gatherer\\.addData\\(.*?\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_listview_data_json_js = r'return JSON.stringify(g_listviews.items.data)'\n",
    "def process_itemlist2(url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        listview_data_json = driver.execute_script(get_listview_data_json_js)\n",
    "    except:\n",
    "        return []\n",
    "    else:\n",
    "        return json.loads(listview_data_json)\n",
    "\n",
    "itemlist_datas = []\n",
    "\n",
    "\n",
    "for ilvl in tqdm(range(min_itemlvl, max_itemlvl), desc=\"Iterating item lists\", leave=False):\n",
    "    u = root_url + f'/items/min-level:{ilvl}/max-level:{ilvl}'\n",
    "    data = process_itemlist2(u)\n",
    "    data_len = len(data)\n",
    "    if data_len == 0:\n",
    "        continue\n",
    "    elif data_len < 1000:\n",
    "        itemlist_datas += data\n",
    "    else:\n",
    "        for qid in item_qualities['id']:\n",
    "            u += f'/quality:{qid}'\n",
    "            itemlist_datas += process_itemlist2(u)\n",
    "\n",
    "            \n",
    "\n",
    "# for u in tqdm(itemlist_urls, desc=\"Iterating item lists for item urls\", leave=False):\n",
    "#     itemlist_data = process_itemlist2(u)\n",
    "\n",
    "#     itemlist_datas.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape itemslists for item urls\n",
    "def process_itemlist(url):\n",
    "    click_next_btn_js = r'next_btn = Array.from(document.querySelectorAll(\"#tab-items > div.listview-band-top > div.listview-nav > a\")).find(x => x.textContent.toLowerCase().startsWith(\"next\")); if(next_btn !== undefined) next_btn.click()'\n",
    "    get_item_links_js = r'return Array.from(document.querySelectorAll(\"#tab-items > div.listview-scroller-horizontal > div > table > tbody > tr > td:nth-child(2) > div > a\")).map(x => x.href)'\n",
    "    driver.get(url)\n",
    "    frames = []\n",
    "    pre_url = \"\"\n",
    "    # TODO check and ensure that less < 1000 items where returned by query\n",
    "    while driver.current_url != pre_url:\n",
    "        item_links = driver.execute_script(get_item_links_js)\n",
    "        frames.append(pd.DataFrame(item_links))\n",
    "        pre_url = driver.current_url\n",
    "        driver.execute_script(click_next_btn_js)\n",
    "\n",
    "    return pd.concat(frames)\n",
    "\n",
    "\n",
    "item_urls_csv_path = Path(output_dir + \"/item_urls.csv\")\n",
    "item_urls_csv_exists = item_urls_csv_path.exists()\n",
    "if (item_urls_csv_exists):\n",
    "    item_urls = pd.read_csv(item_urls_csv_path, header=None).rename(columns={0: \"url\"})\n",
    "else:\n",
    "    item_url_frames = []\n",
    "    for u in tqdm(itemlist_urls, desc=\"Iterating item lists for item urls\", leave=False):\n",
    "        item_url_frames.append(process_itemlist(u))\n",
    "\n",
    "    item_urls = pd.concat(item_url_frames).drop_duplicates().rename(columns={0: \"url\"})\n",
    "    item_urls.sort_values(by=['url'], inplace=True, ignore_index=True)\n",
    "    item_urls.to_csv(item_urls_csv_path, sep=';', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26760d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape item XML setup\n",
    "item_xml_dir = Path(output_dir + \"/itemxml\")\n",
    "item_xml_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_item_xml_info(item_url):\n",
    "    idx1 = item_url.index('item=', len(root_url))\n",
    "    idx2 = item_url.index('/', idx1)\n",
    "    item_xml_url = item_url[:idx2] + \"&xml\"\n",
    "    li = item_xml_url.index(r'item=') + len(r'item=')\n",
    "    ri = item_xml_url.index(r'&xml')\n",
    "    item_id_str = item_xml_url[li:ri]\n",
    "    item_xml_filename = item_id_str + r'.xml'\n",
    "    item_xml_filepath = Path(str(item_xml_dir) + '/' +\n",
    "                             item_xml_filename).absolute()\n",
    "    return {r'url': item_xml_url, r'filepath': item_xml_filepath}\n",
    "\n",
    "def download_item_xml(item_url, overwrite=False):\n",
    "    item_xml_info = get_item_xml_info(item_url)\n",
    "    item_xml_exists = item_xml_info['filepath'].exists()\n",
    "    if (not item_xml_exists or overwrite):\n",
    "        rsp = requests.get(item_xml_info['url'])\n",
    "        rsp.raise_for_status()\n",
    "        item_xml_info['filepath'].write_bytes(rsp.content)\n",
    "    return item_xml_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491692ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape item XML download\n",
    "item_xml_paths = {}\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=(os.cpu_count() - 1)) as executor:\n",
    "    fail_count = -1\n",
    "    while fail_count != 0:\n",
    "        fail_count = 0\n",
    "        futures = [executor.submit(download_item_xml, u, False) for u in item_urls['url']]\n",
    "        for future in tqdm(iterable=concurrent.futures.as_completed(futures), desc=\"Downloading Item XML\", total=len(futures), leave=False):\n",
    "            try:\n",
    "                fres = future.result()\n",
    "            except:\n",
    "                fail_count += 1\n",
    "            else:\n",
    "                item_xml_paths[str(fres['filepath'])] = 1\n",
    "item_xml_paths = pd.DataFrame([k for k in item_xml_paths.keys()])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutdown\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing item XML\n",
    "json_dir = Path(output_dir + \"/itemjson\")\n",
    "json_dir.mkdir(parents=True, exist_ok=True)\n",
    "jsonequip_dir = Path(output_dir + \"/jsonequip\")\n",
    "jsonequip_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def parse_item_xml(path, overwrite_json=False):\n",
    "    root = ET.parse(path).find(\".//item\")\n",
    "    class_elem = root.find(\"class\")\n",
    "    subclass_elem = root.find(\"subclass\")\n",
    "    quality_elem = root.find(\"quality\")\n",
    "    icon_elem = root.find(\"icon\")\n",
    "    inventorySlot_elem = root.find(\"inventorySlot\")\n",
    "    parsedItem = {\n",
    "        \"id\": int(root.attrib['id']),\n",
    "        \"name\": root.findtext(\"name\"),\n",
    "        \"level\": int(root.findtext(\"level\")),\n",
    "        \"quality_id\": int(quality_elem.attrib['id']),\n",
    "        \"quality_name\": quality_elem.text,\n",
    "        \"class_id\": int(class_elem.attrib['id']),\n",
    "        \"class_name\": class_elem.text,\n",
    "        \"subclass_id\": int(subclass_elem.attrib['id']),\n",
    "        \"subclass_name\": subclass_elem.text,\n",
    "        \"icon_displayId\": int(icon_elem.attrib['displayId']),\n",
    "        \"icon_name\": icon_elem.text,\n",
    "        \"inventorySlot_id\": int(inventorySlot_elem.attrib['id']),\n",
    "        \"inventorySlot_name\": inventorySlot_elem.text,\n",
    "        \"htmlTooltip\": root.findtext(\"htmlTooltip\"),\n",
    "        \"link\": root.findtext(\"link\")\n",
    "    }\n",
    "    json_str = root.findtext(\"json\")\n",
    "    if (json_str):\n",
    "        json_filepath = json_dir.joinpath(\"{}.json\".format(parsedItem['id']))\n",
    "        if(not json_filepath.exists() or overwrite_json):\n",
    "            json_filepath.write_text('{' + json_str + '}')\n",
    "\n",
    "    jsonequip_str = root.findtext(\"jsonEquip\")\n",
    "    if (jsonequip_str):         \n",
    "            jsonequip_filepath = jsonequip_dir.joinpath(\"{}.equip.json\".format(parsedItem['id']))\n",
    "            if(not jsonequip_filepath.exists() or overwrite_json):\n",
    "                jsonequip_filepath.write_text('{' + jsonequip_str + '}')\n",
    "    return parsedItem\n",
    "\n",
    "fail_count = 0\n",
    "parsed_item_xml = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=(os.cpu_count() - 1)) as executor:\n",
    "    futures = [executor.submit(parse_item_xml, p) for p in item_xml_paths]\n",
    "    for future in tqdm(iterable=concurrent.futures.as_completed(futures), desc=\"Parsing Item XML\", total=len(futures), leave=False):\n",
    "        try:\n",
    "            fres = future.result()\n",
    "        except:\n",
    "            fail_count += 1\n",
    "        else:\n",
    "            parsed_item_xml.append(fres)\n",
    "items = pd.DataFrame.from_records(parsed_item_xml, index='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72984af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_jsonequip(fp):\n",
    "        with fp.open() as f:\n",
    "            data = json.load(f)\n",
    "            data[\"item_id\"] = int(Path(fp.stem).stem)\n",
    "            return data\n",
    "\n",
    "jsonequips = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=(os.cpu_count() - 1)) as executor:\n",
    "    futures = []\n",
    "    for fp in tqdm(iterable=jsonequip_dir.iterdir(), desc=\"Starting jsonequip parse futures\", leave=False):\n",
    "        futures.append(executor.submit(parse_jsonequip, fp))\n",
    "\n",
    "    for future in tqdm(iterable=concurrent.futures.as_completed(futures), desc=\"Parsing item jsonequips\", total=len(futures), leave=False):\n",
    "        df = future.result()\n",
    "        jsonequips.append(df)\n",
    "\n",
    "jsonequips = pd.DataFrame.from_records(jsonequips).drop(columns={'appearances','displayid'})\n",
    "jsonequips.set_index('item_id', inplace=True)\n",
    "jsonequips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b388550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Convert jsonequips to long format\n",
    "temp3 = \"abc\"\n",
    "print(f'{temp3=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weapon_dps(item_id):\n",
    "        try:\n",
    "            row = jsonequips.loc[item_id]\n",
    "        except:\n",
    "            return pd.NA\n",
    "        else:\n",
    "            if pd.notna(row['dps']):\n",
    "                return row['dps']\n",
    "            if pd.notna(row['mledps']):\n",
    "                print(\"used mledps\")\n",
    "                return row['mledps']\n",
    "            if pd.notna(row['rgddps']):\n",
    "                print(\"used rgddps\")\n",
    "                return row['rgddps']\n",
    "            # TODO Calculate from damage and speed numbers if all else fails\n",
    "            return pd.NA\n",
    "\n",
    "weapons = items[items['class_name'] == 'Weapons'][['subclass_name','name', 'level','quality_id','quality_name']].reset_index()\n",
    "weapons.rename(columns={'subclass_name':'subclass', 'quality_name':'quality', 'level':'item level', 'id':'item_id'}, inplace=True)\n",
    "\n",
    "weapons['quality_color'] = pd.Series([(lambda qid: item_qualities_palette[qid])(qid) for qid in weapons['quality_id']])\n",
    "weapons['dps'] = pd.Series([get_weapon_dps(item_id) for item_id in weapons['item_id']])\n",
    "weapons = weapons[weapons['dps'].notna()].sort_values('item_id', ascending=True).reset_index().drop(columns='index')\n",
    "weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weapons_by_subclass = {}\n",
    "for subclass in weapons['subclass'].drop_duplicates().sort_values():\n",
    "    weapons_by_subclass[subclass] = weapons[weapons['subclass'] == subclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(rc={'figure.figsize':(16,9)})\n",
    "sns.lineplot(data=weapons_by_subclass['Daggers'], x='item level',y='dps', hue='quality_color', legend=None, sort=True).set_title('Daggers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
